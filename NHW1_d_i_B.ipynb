{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         a      b      c      d       e      f  O\n",
      "0    63.03  22.55  39.61  40.48   98.67  -0.25  1\n",
      "1    39.06  10.06  25.02  29.00  114.41   4.56  1\n",
      "2    68.83  22.22  50.09  46.61  105.99  -3.53  1\n",
      "3    69.30  24.65  44.31  44.64  101.87  11.21  1\n",
      "4    49.71   9.65  28.32  40.06  108.17   7.92  1\n",
      "..     ...    ...    ...    ...     ...    ... ..\n",
      "205  67.29  16.72  51.00  50.57  137.59   4.96  0\n",
      "206  51.33  13.63  33.26  37.69  131.31   1.79  0\n",
      "207  65.76  13.21  44.00  52.55  129.39  -1.98  0\n",
      "208  40.41  -1.33  30.98  41.74  119.34  -6.17  0\n",
      "209  48.80  18.02  52.00  30.78  139.15  10.44  0\n",
      "\n",
      "[210 rows x 7 columns]\n",
      "        a      b       c      d       e       f  O\n",
      "0   69.56  15.40   74.44  54.16  105.07   29.70  1\n",
      "1   89.50  48.90   72.00  40.60  134.63  118.35  1\n",
      "2   85.29  18.28  100.74  67.01  110.66   58.88  1\n",
      "3   60.63  20.60   64.54  40.03  117.23  104.86  1\n",
      "4   60.04  14.31   58.04  45.73  105.13   30.41  1\n",
      "..    ...    ...     ...    ...     ...     ... ..\n",
      "95  47.90  13.62   36.00  34.29  117.45   -4.25  0\n",
      "96  53.94  20.72   29.22  33.22  114.37   -0.42  0\n",
      "97  61.45  22.69   46.17  38.75  125.67   -2.71  0\n",
      "98  45.25   8.69   41.58  36.56  118.55    0.21  0\n",
      "99  33.84   5.07   36.64  28.77  123.95   -0.20  0\n",
      "\n",
      "[100 rows x 7 columns]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 1 1 0 1 0 0 1 0 0 1 1 1 0 0]\n",
      "[1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
      " 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
      " 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "11\n",
      "26\n",
      "0.11\n",
      "0.12380952380952381\n",
      "[  1   6  11  16  21  26  31  36  41  46  51  56  61  66  71  76  81  86\n",
      "  91  96 101 106 111 116 121 126 131 136 141 146 151 156 161 166 171 176\n",
      " 181 186 191 196]\n",
      "40\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n",
      "[[0.13 0.13 0.13 0.14 0.14 0.12 0.11 0.11 0.11 0.11]\n",
      " [0.09 0.09 0.08 0.08 0.08 0.06 0.07 0.08 0.09 0.09]\n",
      " [0.11 0.11 0.12 0.12 0.12 0.12 0.12 0.11 0.11 0.11]\n",
      " [0.13 0.11 0.09 0.09 0.09 0.1  0.1  0.09 0.09 0.09]\n",
      " [0.12 0.1  0.1  0.11 0.1  0.11 0.11 0.11 0.11 0.11]\n",
      " [0.1  0.1  0.11 0.1  0.11 0.1  0.11 0.11 0.11 0.11]\n",
      " [0.12 0.12 0.11 0.12 0.12 0.12 0.12 0.12 0.12 0.12]\n",
      " [0.11 0.11 0.11 0.1  0.1  0.12 0.12 0.12 0.11 0.12]\n",
      " [0.14 0.12 0.11 0.12 0.11 0.12 0.12 0.12 0.12 0.12]\n",
      " [0.12 0.12 0.12 0.11 0.12 0.12 0.12 0.12 0.12 0.12]\n",
      " [0.12 0.13 0.11 0.11 0.13 0.12 0.13 0.13 0.13 0.13]\n",
      " [0.13 0.13 0.12 0.12 0.12 0.13 0.14 0.13 0.13 0.12]\n",
      " [0.14 0.13 0.12 0.13 0.13 0.13 0.14 0.14 0.15 0.15]\n",
      " [0.13 0.12 0.13 0.13 0.11 0.12 0.12 0.13 0.12 0.12]\n",
      " [0.14 0.13 0.13 0.13 0.13 0.14 0.13 0.13 0.13 0.13]\n",
      " [0.12 0.14 0.12 0.11 0.11 0.12 0.12 0.12 0.13 0.12]\n",
      " [0.15 0.13 0.13 0.14 0.14 0.13 0.13 0.13 0.13 0.11]\n",
      " [0.15 0.15 0.16 0.15 0.16 0.14 0.13 0.13 0.12 0.12]\n",
      " [0.2  0.18 0.16 0.16 0.16 0.13 0.14 0.14 0.15 0.16]\n",
      " [0.18 0.15 0.15 0.15 0.14 0.14 0.15 0.15 0.15 0.15]\n",
      " [0.2  0.2  0.17 0.18 0.2  0.18 0.17 0.18 0.17 0.18]\n",
      " [0.21 0.18 0.14 0.13 0.16 0.17 0.17 0.17 0.16 0.17]\n",
      " [0.19 0.19 0.17 0.19 0.19 0.18 0.18 0.19 0.19 0.19]\n",
      " [0.2  0.18 0.18 0.17 0.17 0.17 0.18 0.16 0.17 0.18]\n",
      " [0.23 0.23 0.22 0.19 0.21 0.2  0.23 0.22 0.23 0.23]\n",
      " [0.24 0.23 0.21 0.2  0.19 0.19 0.18 0.19 0.2  0.21]\n",
      " [0.27 0.27 0.26 0.25 0.26 0.26 0.25 0.26 0.25 0.25]\n",
      " [0.28 0.28 0.28 0.28 0.28 0.29 0.28 0.28 0.28 0.28]\n",
      " [0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3 ]\n",
      " [0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3 ]\n",
      " [0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3 ]\n",
      " [0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3 ]\n",
      " [0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3 ]\n",
      " [0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3 ]\n",
      " [0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3 ]\n",
      " [0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3 ]\n",
      " [0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3 ]\n",
      " [0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3 ]\n",
      " [0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3 ]\n",
      " [0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3 ]]\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.13809524 0.14761905 0.15238095 0.15238095 0.14761905 0.15238095\n",
      "  0.15238095 0.14761905 0.14761905 0.13333333]\n",
      " [0.12857143 0.13809524 0.14761905 0.14761905 0.16666667 0.16190476\n",
      "  0.17619048 0.17142857 0.18095238 0.16190476]\n",
      " [0.14285714 0.14761905 0.15714286 0.15714286 0.15238095 0.13809524\n",
      "  0.14285714 0.14761905 0.14761905 0.14761905]\n",
      " [0.15714286 0.13809524 0.13809524 0.12857143 0.13333333 0.13333333\n",
      "  0.12857143 0.13809524 0.14285714 0.14285714]\n",
      " [0.16190476 0.14761905 0.14285714 0.13809524 0.13809524 0.13809524\n",
      "  0.14285714 0.14761905 0.14761905 0.15238095]\n",
      " [0.15714286 0.15714286 0.14761905 0.15238095 0.14761905 0.16190476\n",
      "  0.16190476 0.15714286 0.15238095 0.15238095]\n",
      " [0.15714286 0.16190476 0.16190476 0.17142857 0.17142857 0.16190476\n",
      "  0.15238095 0.14285714 0.14285714 0.15238095]\n",
      " [0.15714286 0.16190476 0.16190476 0.16666667 0.15714286 0.15238095\n",
      "  0.15714286 0.14761905 0.13809524 0.13809524]\n",
      " [0.16666667 0.16190476 0.15238095 0.14761905 0.15238095 0.16666667\n",
      "  0.16666667 0.15714286 0.15714286 0.15714286]\n",
      " [0.15238095 0.15238095 0.15714286 0.15714286 0.15714286 0.16666667\n",
      "  0.17619048 0.17619048 0.17142857 0.16190476]\n",
      " [0.17619048 0.15714286 0.17142857 0.16666667 0.16190476 0.17142857\n",
      "  0.16666667 0.17619048 0.17619048 0.17142857]\n",
      " [0.17142857 0.16666667 0.16190476 0.18095238 0.17142857 0.17619048\n",
      "  0.16666667 0.17142857 0.17619048 0.16666667]\n",
      " [0.18571429 0.17619048 0.16666667 0.17142857 0.18095238 0.17142857\n",
      "  0.17142857 0.15714286 0.15714286 0.16666667]\n",
      " [0.18095238 0.16190476 0.17142857 0.17142857 0.17619048 0.17619048\n",
      "  0.16666667 0.17142857 0.17619048 0.16666667]\n",
      " [0.17619048 0.17142857 0.17619048 0.16666667 0.17619048 0.16666667\n",
      "  0.16190476 0.16190476 0.16190476 0.17619048]\n",
      " [0.17142857 0.17619048 0.16666667 0.18095238 0.17619048 0.17619048\n",
      "  0.16666667 0.16666667 0.17142857 0.17142857]\n",
      " [0.15714286 0.17142857 0.16190476 0.16190476 0.16190476 0.15714286\n",
      "  0.14761905 0.15714286 0.16666667 0.18095238]\n",
      " [0.16190476 0.16190476 0.16666667 0.16190476 0.17619048 0.17142857\n",
      "  0.16666667 0.17142857 0.16666667 0.15714286]\n",
      " [0.18095238 0.16190476 0.16190476 0.17619048 0.17619048 0.17142857\n",
      "  0.17619048 0.18095238 0.17619048 0.18095238]\n",
      " [0.17619048 0.16666667 0.19047619 0.16190476 0.14761905 0.16666667\n",
      "  0.17142857 0.16190476 0.16190476 0.17142857]\n",
      " [0.19047619 0.16666667 0.15238095 0.14761905 0.14285714 0.14761905\n",
      "  0.15238095 0.15238095 0.15714286 0.15238095]\n",
      " [0.21904762 0.20952381 0.18095238 0.15714286 0.15238095 0.15238095\n",
      "  0.14285714 0.15714286 0.16666667 0.17619048]\n",
      " [0.20952381 0.19047619 0.19047619 0.16666667 0.16666667 0.18095238\n",
      "  0.16666667 0.16666667 0.16666667 0.16666667]\n",
      " [0.23809524 0.23333333 0.21428571 0.1952381  0.1952381  0.18095238\n",
      "  0.2047619  0.1952381  0.18571429 0.2       ]\n",
      " [0.24761905 0.23333333 0.22380952 0.21904762 0.22380952 0.21904762\n",
      "  0.20952381 0.2047619  0.20952381 0.21428571]\n",
      " [0.2952381  0.27619048 0.26666667 0.25714286 0.25238095 0.26190476\n",
      "  0.24761905 0.24761905 0.24761905 0.24761905]\n",
      " [0.32380952 0.31904762 0.30952381 0.30952381 0.30952381 0.3047619\n",
      "  0.3        0.30952381 0.30952381 0.30952381]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.33333333\n",
      "  0.33333333 0.33333333 0.33333333 0.33333333]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.33333333\n",
      "  0.33333333 0.33333333 0.33333333 0.33333333]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.33333333\n",
      "  0.33333333 0.33333333 0.33333333 0.33333333]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.33333333\n",
      "  0.33333333 0.33333333 0.33333333 0.33333333]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.33333333\n",
      "  0.33333333 0.33333333 0.33333333 0.33333333]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.33333333\n",
      "  0.33333333 0.33333333 0.33333333 0.33333333]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.33333333\n",
      "  0.33333333 0.33333333 0.33333333 0.33333333]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.33333333\n",
      "  0.33333333 0.33333333 0.33333333 0.33333333]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.33333333\n",
      "  0.33333333 0.33333333 0.33333333 0.33333333]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.33333333\n",
      "  0.33333333 0.33333333 0.33333333 0.33333333]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.33333333\n",
      "  0.33333333 0.33333333 0.33333333 0.33333333]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.33333333\n",
      "  0.33333333 0.33333333 0.33333333 0.33333333]]\n",
      "       p1    p2    p3    p4    p5    p6    p7    p8    p9   p10\n",
      "1    0.13  0.13  0.13  0.14  0.14  0.12  0.11  0.11  0.11  0.11\n",
      "6    0.09  0.09  0.08  0.08  0.08  0.06  0.07  0.08  0.09  0.09\n",
      "11   0.11  0.11  0.12  0.12  0.12  0.12  0.12  0.11  0.11  0.11\n",
      "16   0.13  0.11  0.09  0.09  0.09  0.10  0.10  0.09  0.09  0.09\n",
      "21   0.12  0.10  0.10  0.11  0.10  0.11  0.11  0.11  0.11  0.11\n",
      "26   0.10  0.10  0.11  0.10  0.11  0.10  0.11  0.11  0.11  0.11\n",
      "31   0.12  0.12  0.11  0.12  0.12  0.12  0.12  0.12  0.12  0.12\n",
      "36   0.11  0.11  0.11  0.10  0.10  0.12  0.12  0.12  0.11  0.12\n",
      "41   0.14  0.12  0.11  0.12  0.11  0.12  0.12  0.12  0.12  0.12\n",
      "46   0.12  0.12  0.12  0.11  0.12  0.12  0.12  0.12  0.12  0.12\n",
      "51   0.12  0.13  0.11  0.11  0.13  0.12  0.13  0.13  0.13  0.13\n",
      "56   0.13  0.13  0.12  0.12  0.12  0.13  0.14  0.13  0.13  0.12\n",
      "61   0.14  0.13  0.12  0.13  0.13  0.13  0.14  0.14  0.15  0.15\n",
      "66   0.13  0.12  0.13  0.13  0.11  0.12  0.12  0.13  0.12  0.12\n",
      "71   0.14  0.13  0.13  0.13  0.13  0.14  0.13  0.13  0.13  0.13\n",
      "76   0.12  0.14  0.12  0.11  0.11  0.12  0.12  0.12  0.13  0.12\n",
      "81   0.15  0.13  0.13  0.14  0.14  0.13  0.13  0.13  0.13  0.11\n",
      "86   0.15  0.15  0.16  0.15  0.16  0.14  0.13  0.13  0.12  0.12\n",
      "91   0.20  0.18  0.16  0.16  0.16  0.13  0.14  0.14  0.15  0.16\n",
      "96   0.18  0.15  0.15  0.15  0.14  0.14  0.15  0.15  0.15  0.15\n",
      "101  0.20  0.20  0.17  0.18  0.20  0.18  0.17  0.18  0.17  0.18\n",
      "106  0.21  0.18  0.14  0.13  0.16  0.17  0.17  0.17  0.16  0.17\n",
      "111  0.19  0.19  0.17  0.19  0.19  0.18  0.18  0.19  0.19  0.19\n",
      "116  0.20  0.18  0.18  0.17  0.17  0.17  0.18  0.16  0.17  0.18\n",
      "121  0.23  0.23  0.22  0.19  0.21  0.20  0.23  0.22  0.23  0.23\n",
      "126  0.24  0.23  0.21  0.20  0.19  0.19  0.18  0.19  0.20  0.21\n",
      "131  0.27  0.27  0.26  0.25  0.26  0.26  0.25  0.26  0.25  0.25\n",
      "136  0.28  0.28  0.28  0.28  0.28  0.29  0.28  0.28  0.28  0.28\n",
      "141  0.30  0.30  0.30  0.30  0.30  0.30  0.30  0.30  0.30  0.30\n",
      "146  0.30  0.30  0.30  0.30  0.30  0.30  0.30  0.30  0.30  0.30\n",
      "151  0.30  0.30  0.30  0.30  0.30  0.30  0.30  0.30  0.30  0.30\n",
      "156  0.30  0.30  0.30  0.30  0.30  0.30  0.30  0.30  0.30  0.30\n",
      "161  0.30  0.30  0.30  0.30  0.30  0.30  0.30  0.30  0.30  0.30\n",
      "166  0.30  0.30  0.30  0.30  0.30  0.30  0.30  0.30  0.30  0.30\n",
      "171  0.30  0.30  0.30  0.30  0.30  0.30  0.30  0.30  0.30  0.30\n",
      "176  0.30  0.30  0.30  0.30  0.30  0.30  0.30  0.30  0.30  0.30\n",
      "181  0.30  0.30  0.30  0.30  0.30  0.30  0.30  0.30  0.30  0.30\n",
      "186  0.30  0.30  0.30  0.30  0.30  0.30  0.30  0.30  0.30  0.30\n",
      "191  0.30  0.30  0.30  0.30  0.30  0.30  0.30  0.30  0.30  0.30\n",
      "196  0.30  0.30  0.30  0.30  0.30  0.30  0.30  0.30  0.30  0.30\n",
      "           p1        p2        p3        p4        p5        p6        p7  \\\n",
      "1    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "6    0.138095  0.147619  0.152381  0.152381  0.147619  0.152381  0.152381   \n",
      "11   0.128571  0.138095  0.147619  0.147619  0.166667  0.161905  0.176190   \n",
      "16   0.142857  0.147619  0.157143  0.157143  0.152381  0.138095  0.142857   \n",
      "21   0.157143  0.138095  0.138095  0.128571  0.133333  0.133333  0.128571   \n",
      "26   0.161905  0.147619  0.142857  0.138095  0.138095  0.138095  0.142857   \n",
      "31   0.157143  0.157143  0.147619  0.152381  0.147619  0.161905  0.161905   \n",
      "36   0.157143  0.161905  0.161905  0.171429  0.171429  0.161905  0.152381   \n",
      "41   0.157143  0.161905  0.161905  0.166667  0.157143  0.152381  0.157143   \n",
      "46   0.166667  0.161905  0.152381  0.147619  0.152381  0.166667  0.166667   \n",
      "51   0.152381  0.152381  0.157143  0.157143  0.157143  0.166667  0.176190   \n",
      "56   0.176190  0.157143  0.171429  0.166667  0.161905  0.171429  0.166667   \n",
      "61   0.171429  0.166667  0.161905  0.180952  0.171429  0.176190  0.166667   \n",
      "66   0.185714  0.176190  0.166667  0.171429  0.180952  0.171429  0.171429   \n",
      "71   0.180952  0.161905  0.171429  0.171429  0.176190  0.176190  0.166667   \n",
      "76   0.176190  0.171429  0.176190  0.166667  0.176190  0.166667  0.161905   \n",
      "81   0.171429  0.176190  0.166667  0.180952  0.176190  0.176190  0.166667   \n",
      "86   0.157143  0.171429  0.161905  0.161905  0.161905  0.157143  0.147619   \n",
      "91   0.161905  0.161905  0.166667  0.161905  0.176190  0.171429  0.166667   \n",
      "96   0.180952  0.161905  0.161905  0.176190  0.176190  0.171429  0.176190   \n",
      "101  0.176190  0.166667  0.190476  0.161905  0.147619  0.166667  0.171429   \n",
      "106  0.190476  0.166667  0.152381  0.147619  0.142857  0.147619  0.152381   \n",
      "111  0.219048  0.209524  0.180952  0.157143  0.152381  0.152381  0.142857   \n",
      "116  0.209524  0.190476  0.190476  0.166667  0.166667  0.180952  0.166667   \n",
      "121  0.238095  0.233333  0.214286  0.195238  0.195238  0.180952  0.204762   \n",
      "126  0.247619  0.233333  0.223810  0.219048  0.223810  0.219048  0.209524   \n",
      "131  0.295238  0.276190  0.266667  0.257143  0.252381  0.261905  0.247619   \n",
      "136  0.323810  0.319048  0.309524  0.309524  0.309524  0.304762  0.300000   \n",
      "141  0.333333  0.333333  0.333333  0.333333  0.333333  0.333333  0.333333   \n",
      "146  0.333333  0.333333  0.333333  0.333333  0.333333  0.333333  0.333333   \n",
      "151  0.333333  0.333333  0.333333  0.333333  0.333333  0.333333  0.333333   \n",
      "156  0.333333  0.333333  0.333333  0.333333  0.333333  0.333333  0.333333   \n",
      "161  0.333333  0.333333  0.333333  0.333333  0.333333  0.333333  0.333333   \n",
      "166  0.333333  0.333333  0.333333  0.333333  0.333333  0.333333  0.333333   \n",
      "171  0.333333  0.333333  0.333333  0.333333  0.333333  0.333333  0.333333   \n",
      "176  0.333333  0.333333  0.333333  0.333333  0.333333  0.333333  0.333333   \n",
      "181  0.333333  0.333333  0.333333  0.333333  0.333333  0.333333  0.333333   \n",
      "186  0.333333  0.333333  0.333333  0.333333  0.333333  0.333333  0.333333   \n",
      "191  0.333333  0.333333  0.333333  0.333333  0.333333  0.333333  0.333333   \n",
      "196  0.333333  0.333333  0.333333  0.333333  0.333333  0.333333  0.333333   \n",
      "\n",
      "           p8        p9       p10  \n",
      "1    0.000000  0.000000  0.000000  \n",
      "6    0.147619  0.147619  0.133333  \n",
      "11   0.171429  0.180952  0.161905  \n",
      "16   0.147619  0.147619  0.147619  \n",
      "21   0.138095  0.142857  0.142857  \n",
      "26   0.147619  0.147619  0.152381  \n",
      "31   0.157143  0.152381  0.152381  \n",
      "36   0.142857  0.142857  0.152381  \n",
      "41   0.147619  0.138095  0.138095  \n",
      "46   0.157143  0.157143  0.157143  \n",
      "51   0.176190  0.171429  0.161905  \n",
      "56   0.176190  0.176190  0.171429  \n",
      "61   0.171429  0.176190  0.166667  \n",
      "66   0.157143  0.157143  0.166667  \n",
      "71   0.171429  0.176190  0.166667  \n",
      "76   0.161905  0.161905  0.176190  \n",
      "81   0.166667  0.171429  0.171429  \n",
      "86   0.157143  0.166667  0.180952  \n",
      "91   0.171429  0.166667  0.157143  \n",
      "96   0.180952  0.176190  0.180952  \n",
      "101  0.161905  0.161905  0.171429  \n",
      "106  0.152381  0.157143  0.152381  \n",
      "111  0.157143  0.166667  0.176190  \n",
      "116  0.166667  0.166667  0.166667  \n",
      "121  0.195238  0.185714  0.200000  \n",
      "126  0.204762  0.209524  0.214286  \n",
      "131  0.247619  0.247619  0.247619  \n",
      "136  0.309524  0.309524  0.309524  \n",
      "141  0.333333  0.333333  0.333333  \n",
      "146  0.333333  0.333333  0.333333  \n",
      "151  0.333333  0.333333  0.333333  \n",
      "156  0.333333  0.333333  0.333333  \n",
      "161  0.333333  0.333333  0.333333  \n",
      "166  0.333333  0.333333  0.333333  \n",
      "171  0.333333  0.333333  0.333333  \n",
      "176  0.333333  0.333333  0.333333  \n",
      "181  0.333333  0.333333  0.333333  \n",
      "186  0.333333  0.333333  0.333333  \n",
      "191  0.333333  0.333333  0.333333  \n",
      "196  0.333333  0.333333  0.333333  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nFrom the plot for k*=16,\\nwe can clearly see that \\nlogp = 0.6 minimizes the training error and the test error though not minimized, is\\nsufficiently low\\nlogp= 0.8 and logp=1 also minimize the test error, but the training error does increase moderately\\n\\nSo\\nlogp=0.6 is an optimal point \\n\\n(we can also include 0.8 and 1 as they don't perform badly either)\\n\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEJCAYAAACOr7BbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd5hU9fXH8fcHECyADWKkCRqiYEUXxIY9gg0VjGADoxJbxC4ajYq9t4CCiQo2wBgMsfPT2BvFigoiIqwaRRGxggvn98cZwroOu3eXnb2zM+f1PPPMzJ177xyW3Tlzv+V8ZWaEEEIIFTVIO4AQQgj5KRJECCGErCJBhBBCyCoSRAghhKwiQYQQQsgqEkQIIYSscpogJPWUNF3STElDsrzeQ9JUSWWS+lZ4rZ2kJyS9K+kdSe1zGWsIIYSfy1mCkNQQGAb0AjoD/SV1rrDbHGAgcG+WU4wGrjazTkA34PNcxRpCCOGXGuXw3N2AmWY2C0DSGKA38M6yHcxsdua1peUPzCSSRmY2MbPft1W9WYsWLax9+/a1FXsIIRSFKVOmfGFmLbO9lssE0RqYW+55KbBtwmN/CyyQ9E+gA/B/wBAzW7KiA9q3b8/kyZNrGmsIIRQlSR+t6LVc9kEoy7akdT0aATsBZwBdgQ3xpqifv4E0SNJkSZPnzZtX0zhDCCFkkcsEUQq0Lfe8DfBJNY59zcxmmVkZ8CCwdcWdzGykmZWYWUnLllmvkEIIIdRQLhPEJKCjpA6SGgP9gAnVOHZtScs+9XejXN9FCCGE3MtZgsh88z8JeBx4FxhnZtMkDZW0P4CkrpJKgYOBEZKmZY5dgjcvPSnpLby56rZcxRpCCOGXVCjlvktKSiw6qUMIoXokTTGzkmyvxUzqEEIIWUWCCCGEkFUu50GEemjWLLj7bigrSzsSaNsWDjkEmjdPO5IQilMkiPA/Tz0FffvCV1+Bss1iqUPLusZOOw2OOAJOOAE22yzdmEIoNtHEFAC45Rb43e+gVSv44ANYujT92yuvQJ8+cPvtsPnmsPPOMHYsLF6c9k8rhOIQCaLI/fQTnHiif0Pv2RNefBE23DDtqPwKpls3uPNO+PhjuPpqKC2Ffv2gXTs4/3yYO7fK04QQVkIkiCI2fz706gXDh8OZZ8K//pWf7f3rrgtnnAHvvw+PPuqJ49JLoX17OPBA+L//8yuOEELtigRRpN57D7bdFp57zr+lX3UVNGyYdlSVa9DAr3ImTPDO9LPOguefhz33hE6d4IYbvP8khFA7IkEUocceg+7dYeFC+M9/YMCAtCOqvvbt4fLLvdnp7ruhRQs49VRo3RqOOQamTk07whDqv0gQRcQMbrwR9tnHP2BffRW23z7tqFZOkyZw2GHwwgvw2mtw+OFw332wzTaeBEePhh9/TDvKEOqnSBBFYvFiGDQITjkFevf2ppkNNkg7qtq11VYwcqR3at94IyxY4FdHbdrA2Wd7s1QIIblIEEXgiy+8nf5vf4PzzoN//AOaNk07qtxZay04+WR491148knYZRe49lr4zW/86unhh2HJCpeeCiEsEwmiwL39NnTt6s1J994LF1/snb3FQILddvOE+NFH8Je/eDPUvvt6srjySoh1pkJYsSL5qChO//43bLcdLFoEzzwD/funHVF6WreGCy/0RDFunPfBDBnizU9HHgkvv7x89nYIwUWCKEBmPmy1d2/YeGOYNMnnDgRYZRU4+GAfvTVtmvfLPPigJ9JttvFmuO++SzvKEPJDJIgC8+OPMHCgd8r+/vfw7LP+7Tn8UufOcPPN3ql9661eoPDYY/3ndcopMH162hGGkK5IEAXkv//1NvfRo2HoUB/uufrqaUeV/5o1gz/+Ed54wycO7r23zy7fZBPv3H/ppbQjDCEdkSAKxGuveTPSG294p+z556dfkbW+kWDHHb0zf+5cL+fxzjs+e/u999KOLoS6FwmiADzwgH+wmfn8hj590o6o/ltvPTj3XL96aNIEDjgAvv467ahCqFtVJghJ62S5rVIXwYXKmfmw1b59YYstvDO6S5e0oyos7drB/ffDzJk+SzuKAoZikuQKYiowD5gBvJ95/KGkqZK2yWVwYcV++AEOPdTH9h9xhI/K+fWv046qMO28sxcCfOghHyobQrFIkiAeA/Y2sxZmti7QCxgHnAAMr+xAST0lTZc0U9KQLK/3yCSaMkl9K7y2RNLrmduE5P+kwvfxx9Cjhy+ec8UVMGoUrLpq2lEVthNPhKOO8iu28ePTjiaEupEkQZSY2ePLnpjZE0APM3sZaLKigyQ1BIbhCaUz0F9S5wq7zQEGAvdmOcUPZrZV5rZ/gjiLwqRJPjP6vfd8/P7ZZ0dndF2QfGRTt24+sW7atLQjCiH3kiSI+ZLOlrRB5nYW8FUmAVTWItsNmGlms8xsMTAG6F1+BzObbWZvVnGekDFmjF85NGniK7/tH2mzTq26Kvzzn7DGGt5pHWtPhEKXJEEcCrQBHgT+BbTLbGsI/L6S41oD5ReFLM1sS2pVSZMlvSzpgGw7SBqU2WfyvAIuqrN0qQ9b7d9/eV2lzTdPO6ri1Lq1jxr76CPvA4qif6GQVZkgzOwLM/uTmXXJNPecZGbzzGyxmc2s5NBsDR/VqXbTzsxK8GR0g6SNssQ20sxKzKykZcuW1Th1/fHdd14a4pJL4OijfXnNAv2n1hs77AB//asvvHTeeWlHE0LuNKpqB0m/Bc4A2pff38x2q+LQUqBtuedtgE+SBmZmn2TuZ0l6GugCfJD0+EIwZ443I731Flx/PQweHP0N+WLQIJgyxQcJdOniZU1CKDRVJgjgfuBW4G9AdS6oJwEdJXUAPgb64VcDVZK0NvC9mS2S1ALYAbiqGu9d7734Ihx4oNdWevhhn80b8stNN3k59aOO8rIcW2yRdkQh1K4kfRBlZnaLmb1qZlOW3ao6yMzKgJOAx4F3gXFmNk3SUEn7A0jqKqkUOBgYIWnZ2JBOwGRJbwD/Aa4ws3dq8O+rl0aPhl13hebNvQx1JIf81KSJlzVZay3vtP7yy7QjCqF2yaoogi/pQuBzYDywaNl2M5uf08iqqaSkxCZPnpx2GCtlyRIv73DVVV507/77YZ110o4qVOWVV3x0WY8e8Oij0CjJdXkIeULSlEx/7y8k+VUekLk/s9w2AzZc2cDCcrNmeR/DQw/B8cf7msqrREGTemHbbb1c+B/+4IsQXXNN2hEVtnfegUce8fLswbVq5fNzaluVCcLMOtT+2wbwK4bHHoNhw/y+YUN/fMIJaUcWquuoo2DqVF/7uksXOOywtCMqLD/95BNDhw+Hp59OO5r8s+22dZwgJO1mZk9JOijb62b2z9oPpzjMmwe33+7fOmfPhvXX95pKyxarCfXTddfBm2/CMcdAp06w9dZpR1T/ffwxjBwJt90Gn37qS8VeeaV/GK61VtrR5Y9cjW6s7ApiZ+ApYL8srxkQCaIazLzDefhwXxN58WLYZRfvbzjggGhOKgSrrOL9RiUlPgJt8uSYs1ITZl58cvhwv2pYuhR69fLlYPfay6+0Q92ospO6vsjXTurvvvMFaIYPh9df99XLBgzwfobOFStThYIwZYqvz9G9OzzxRCT/pBYs8BF8t9zitcbWXdcnh/7xj7Bh9HjmzEp1UktqAvThlxPlhtZWgIVo+nRPCqNG+UIzm2/uTUqHHQZNm6YdXcilbbbxZpEjj4QzzvABB2HFXn/d/1buuQe+/94T6+jRXkEgqhSnK8kopn8BXwNTKDfMNfxSWRlMmOC/7E8+6d8c+/b1TucddohZ0MXkiCN8Gdjrr/dO64ED044ovyxa5HNIhg3zVftWW81rW51wQvTd5JMkCaKNmcVUrUp8+ql3oo0c6Z1qbdv6esZHH+1LV4bidNVVvkb4ccd5c2K3bmlHlL7Zs2HECO9P+OIL6NjRk+iAAbD22mlHFypKkiBelLS5mb2V82jqETN49ln/BjR+vF897LWXXz3ss090pAWfMDd2rFfgPegg77QuxlX/li6Fxx/3v42HH/Yr6d69/Wpht92gQZJ6DiEVSRLEjsBASR/iTUwCzMyKsvLMwoVw113+y/7OO/6tZ/Bg70jr2DHt6EK+adHCR+Jst523qT/5JDRunHZUdePLL5cP5541y6+m//xnL3TYtm3Vx4f0JUkQvXIeRT3w1lueFO66y0cmlZTAHXfAIYd4+2kIK7Lllv670q8fnHKK/x4VKjNf9XD4cF/gatEiL0Fy2WU+9LdYkmOhqGyiXHMzWwh8U4fx5JXFi31xmOHD4fnnfURFv35+ady1a9rRhfrkkEN8pvVVV3mn9bHHph1R7fr+e08Iw4f7MN+mTb0P7vjjYbPN0o4u1FRlVxD3Avvio5eMny8AVNC1mObMWd6R9vnnsNFGXl9n4EAfmx1CTVx2mQ/pPPFE2HRT2H77tCNaeTNmeBPSHXf4PIZNN/V+ucMP92rEoX5bYYIws30z90VRi2npUl+tbfhw+Pe/fdu++/rVwp57RkdaWHkNG8J99/lopj59/Jt2q1ZpR1V9ZWXe2TxsGEyc6J3xffr438pOO8Vw7kKSqDBxZgGfjsD/pq2Y2bO5CqouLVzoVwq33AIzZ3pphLPP9k7nDTZIO7pQaNZZxzutu3f3D9Wnn/Z1JeqDzz7zv5URI2DuXGjTBi6+2GtPFePorGKQZCb1McBgfMnQ14HuwEtAVUuO1gs//OAlmrt1g4su8j/a+vIHG+qnzTbzmcJ9+nhz02235e+3bjPvfxs+3PvjfvoJ9tjDZ4fvt1+sfVHokvz3Dga6Ai+b2a6SNgEuym1YdWe99eCDD2LYXahbBx0E550Hl1zipTmOPz7tiH7um2+89MXw4T6Cb801PZkddxxsvHHa0YW6kiRB/GhmP0pCUhMze09SQf2KRHIIabjoIu+0Pvlkv6rYaae0I4Jp07y5dfRoTxJdunizUr9+sMYaaUcX6lqSBFEqaS3gQWCipK+AT3IbVgiFr0EDuPtub97s29dnWqfxZWXx4uWL8TzzjM9VOOQQ73Tedtv8bf4KuVetct+SdgbWBB4zs8U5i6oG8rXcdwhVefdd/yD+7W/huefqbuJlaenyxXj++19fjOf44311vFjHonhUVu670sGbkhpIenvZczN7xswmJE0OknpKmi5ppqQhWV7vIWmqpDJJfbO83lzSx5L+muT9QqiPOnXyK4kpU7yNP5dLtJh5uY8+fTwhXHKJV099+GEfxXfWWZEcwnKVJggzWwq8IalddU8sqSEwDC/V0RnoL6niEjlzgIH4pLxsLgaeqe57h1Df7L+/90mMHg0331z751+wwEcederko5CeeQZOP92TwsMPw957R4HJ8EtJ+iDWB6ZJehX4btlGM9u/iuO6ATPNbBaApDFAb+CdcueYnXltacWDJW0DrAc8BmS9/AmhkJx3nq8hcdppvsDUrruu/Dlff90ntN17byzGE6ovSYKo6ZDW1sDccs9LgW2THCipAXAtcASwew3fP4R6pUED//Du3t0/wCdP9mag6vrxR1+MZ/jw5YvxHHaY9y/EYjyhOpIUkNg70/fwvxuwd4Ljso19SNq6egLwiJnNrWwnSYMkTZY0ed68eQlPHUL+atbMRxSVlXn10++/T37shx/6pM+2bX1Fuy++8MV4Pv7YO6IjOYTqSpIg9syyLUkJ8FKg/KC9NiQfHrsdcJKk2cA1wJGSrqi4k5mNNLMSMytpGT1roUB07Og1m954w8tYVNZpvXQpPPqoz2reaCO4+mqfTzFxIrz3npcXj5XaQk1VVu77ePyb/IaS3iz3UjPghQTnngR0lNQB+BjoBxyaJCgzO6xcHAOBEjP7xSioEApVr16+bO255/o3/zPO+PnrX3zhFVRvucWvHNZbz/swjj02Jn6G2lNVue9HgcuB8h/O35jZ/KpObGZlkk4CHgcaAreb2TRJQ4HJZjZBUldgPLA2sJ+ki8xs05r+Y0IoJEOG+BoSZ5/tiw7tsQe8+qr3LYwdu3wxnssvj8V4Qm5Ua6JcPouJcqEQffutrxtRWgodOnjCaNoUjjwyFuMJtaOyiXJRizGEPNa06fI1rRct8quHww/3zuwQci0SRAh5bsMNfSRSw4ZRFynUrUgQIdQDse5CSEOihTQljSt/H0IIofAlXWn5N5n7jrkKJIQQQn5JmiBCCCEUmUgQIYQQsooEEUIIIaukCSIG14UQQpFJmiCurnAfQgihwCVKEGZ2b/n7EEIIhS/6IEIIIWQVCSKEEEJWkSBCCCFkVWWCkLSepL9LejTzvLOko3MfWgghhDQluYK4E1/0p1Xm+QzglFwFFEIIIT8kSRAtzGwcsBR8pThgSU6jCiGEkLokCeI7SesCBiCpO/B1TqMKIYSQuiRV5k8DJgAbSXoBaAn0zWlUIYQQUldlgjCzqZJ2BjbGS25MN7Ofch5ZCCGEVFWZICQdWWHT1pIws9E5iimEEEIeSNIH0bXcbSfgQmD/JCeX1FPSdEkzJQ3J8noPSVMllUnqW277BpKmSHpd0jRJxyX614QQQqg1SZqY/lT+uaQ1gbuqOk5SQ2AYsCdQCkySNMHM3im32xxgIHBGhcM/BbY3s0WSmgJvZ479pKr3DSGEUDtqMpP6e5ItPdoNmGlms8xsMTAG6F1+BzObbWZvkhlCW277YjNblHnapIZxJvPFF3D00fDWWzl7ixBCqI+S9EH8m8wQV/yDujMwLsG5WwNzyz0vBbZNGpiktsDD+HrYZ2a7epA0CBgE0K5du6SnrngSGD8ePvoIJk705yGEEBINc72m3OMy4CMzK01wXLZPWsuyLSszmwtsIakV8KCkf5jZZxX2GQmMBCgpKUl87p9Zd1248EIYPBgmTIDevas8JIQQikGVTTdm9ky52wsJkwP4FUPbcs/bANXuQ8hcOUzDO8hz4/jjoVMnOP10WLSo6v1DCKEIrDBBSPpG0sIst28kLUxw7klAR0kdJDUG+uET7qokqY2k1TKP1wZ2AKYnObZGVlkFrrsOPvgAbropZ28TQgj1yQoThJk1M7PmWW7NzKx5VSfO1Gw6CS/09y4wzsymSRoqaX8ASV0llQIHAyMkTcsc3gl4RdIbwDPANWaW217knj1h773h4ovhs8+q3j+EEAqczKpuupe0NbAj3ofwvJm9luvAqqukpMQmT568cieZPh022wwGDoTbbquVuEIIIZ9JmmJmJdleS7IexF+AUcC6QAvgTknn1W6IeWLjjeFPf4K//x1ey7scGEIIdarKKwhJ7wJdzOzHzPPVgKlm1qkO4kusVq4gABYsgI4doXNnePrpGPYaQihoK3UFAcwGVi33vAnwQS3ElZ/WWsv7IZ59Fh54IO1oQgghNZWNYrpZ0k3AImCapDsl3QG8DXxbVwGm4phjYPPN4cwz4ccf044mhBBSUdlEuWXtNVOA8eW2P52zaPJFo0Zwww2w++4+/PXcc9OOKIQQ6lyiUUz1Qa31QZR34IFefmPGDGjVqur9QwihnlnZPojidc018NNPcQURQihKkSAqs9FGcMopMGoUTJqUdjQhhFCnIkFU5c9/hvXW80RRIM1xIYSQRLUThKTLJJ0tad1cBJR3mjeHSy+FF1+EMWPSjiaEEOpMTa4gXsXLfl9fy7Hkr4EDoUsXOOss+P77tKMJIYQ6kaTUxg7ln5vZg8DLZnZkzqLKNw0bwo03QmkpXH112tGEEEKdSHIFcXPCbYVtp53g4IPhyith7tyq9w8hhHpuhRPlJG0HbA+0lHRauZeaAw1zHVheuuoqX3VuyBC45560owkhhJyq7AqiMdAUTyLNyt0WAn1zH1oeat8ezjgD7r0XXnop7WhCCCGnklRz3cDMPso8bgA0NbMkK8rVqZzMpM7m22/ht7+FNm3g5ZehQYwUDiHUXys7k/pySc0lrQG8A0yXdGatRlifNG0KV1zhE+fuvjvtaEIIIWeSJIjOmSuGA4BHgHbAETmNKt8dfjh06+Z9Ed8WdmHbEELxSpIgVpG0Cp4g/mVmP+FLjxavBg282uunn/rVRAghFKAkCWIEvmjQGsCzkjbAO6qL23bbwaGHekG/2bPTjiaEEGpdlQnCzG4ys9Zmtre5j4Bdk5xcUk9J0yXNlDQky+s9JE2VVCapb7ntW0l6SdI0SW9KOqRa/6q6csUVfjVx1llpRxJCCLUuyUzq9ST9XdKjmeedgQEJjmsIDAN6AZ2B/pljy5sDDATurbD9e+BIM9sU6AncIGmtqt6zzrVtC2efDfff70uUhhBCAUnSxHQn8DiwbMWcGcApCY7rBsw0s1lmthgYA/Quv4OZzTazN4GlFbbPMLP3M48/AT4HWiZ4z7p35pmeKE45BZYsSTuaEEKoNUkSRAszG0fmQ9zMyoAkn4StgfI1KUoz26pFUjd80t4H1T22Tqy+upffeO01uOOOtKMJIYRakyRBfJcp7W0AkroDXyc4Tlm2VWv0k6T1gbuAo8xsaZbXB0maLGnyvHnzqnPq2tWvH2y/va8dsTD670MIhSFJgjgNmABsJOkFYDRwcoLjSoG25Z63AT5JGpik5sDDwHlm9nK2fcxspJmVmFlJy5YptkBJPuz188/hkkvSiyOEEGpRkgQxDdgZL9z3R2BT4L0Ex00COkrqIKkx0A9PNFXK7D8eGG1m9yc5JnVdu8KAAZ4oZs5MO5oQQlhpSRLES2ZWZmbTzOztzES5KivVZfoqTsI7uN8FxpnZNElDJe0PIKmrpFLgYGCEpGmZw38P9AAGSno9c9uqBv++unXZZdC4sRf0CyGEeq6yct+/xjuVV5PUheV9Cs2B1ZOc3MwewctzlN/2l3KPJ+FNTxWPuxuof4WOWrWCc8/1vognn4Tdd087ohBCqLEVVnOVNACfo1CCNxctSxALgVFm9s+6CDCpOqvmWpUff4ROnbyo32uvQaMV5uAQQkhdjaq5mtkoM9sVGGhmu5nZrplb73xLDnll1VV9WdK334bbbks7mhBCqLEkpTYeqItACkqfPrDzznD++fDVV2lHE0IINRKr3eTCsmGv8+fD0KFpRxNCCDUSCSJXttoKjjkG/vpXeC/JqOAQQsgviRKEpE3K34eELrnES3GcfnrakYQQQrUlvYK4t8J9SOJXv/J+iEcegcceSzuaEEKoluo2MWWrrxQqc/LJ8JvfwKmnwk8/pR1NCCEkFn0Quda4MVx7rfdD3HJL2tGEEEJikSDqwn77wR57wIUXwpdfph1NCCEkUt0EUa1y3SFDguuvh6+/hgsuSDuaEEJIJGmCUIX7UF2bbQbHHQe33grTplW9fwghpCxpgtipwn2oiYsugmbNvMN6BTWwQgghXyRKEGb2bfn7UEMtWng/xMSJ8NBDaUcTQgiVik7qunbCCbDJJj55bvHitKMJIYQVigRR11ZZBa67Dt5/H26+Oe1oQghhhSJBpKFXL78NHerrWIcQQh6qbEW5t6hkWKuZbZGTiIrFddfB5pt7KY4RI9KOJoQQfqGy5c72zdyfmLm/K3N/GPB9ziIqFptsAiee6M1MJ5wAW26ZdkQhhPAzK1xy9H87SC+Y2Q5VbUtb3iw5Wh1ffQUdO/qVxFNP+YS6EEKoQzVacrScNSTtWO5k2wNrJHzjnpKmS5opaUiW13tImiqpTFLfCq89JmmBpMIdD7r22t4P8fTTMH582tGEEMLPJEkQRwPDJM2W9CEwHPhDVQdJaggMA3oBnYH+kjpX2G0OMJDsZcSvBo5IEF/9NmiQz7I+4wz48ce0owkhhP9Jsib1FDPbEtgC2MrMtjKzqQnO3Q2YaWazzGwxMAboXeHcs83sTWBplvd9EvgmyT+iXmvUyOs0ffihL1MaQgh5osoEIWk9SX8HxprZ15I6Szo6wblbA3PLPS/NbAsV7bEH7L8/XHopfPpp2tGEEAKQrInpTuBxoFXm+QzglATHZetxrdUCRJIGSZosafK8efNq89R179prYdEi+POf044khBCAZAmihZmNI9MMZGZlwJIEx5UCbcs9bwN8Uu0IK2FmI82sxMxKWrZsWZunrnu/+Q0MHgx33gn1bTRWCKEgJUkQ30lal8y3f0ndga8THDcJ6Cipg6TGQD9gQo0jLQbnnecF/U45Jaq9hhBSlyRBnIZ/sG8k6QVgNPCnqg7KXGmchDdPvQuMM7NpkoZK2h9AUldJpcDBwAhJ/1soQdJzwP3A7pJKJe1VzX9b/bPmmt4P8cILMHZs2tGEEIpcpRPlJDUAugOvAhvj/QrTzeynugkvuXo5US6bJUtgm21g/nxfx3r11dOOKIRQwGo8Uc7MlgLXmlmZmU0zs7fzMTkUlIYN4cYbYe5cuOaatKMJIRSxJE1MT0jqI0UdiDqz887Qpw9ceSWUlqYdTQihSCXtg7gfWCRpoaRvJC3McVzh6qu9uWnILyqUhBBCnUgyk7qZmTUws8Zm1jzzvHldBFfUOnSA006De+6Bl19OO5oQQhGKBYPy2TnnwPrr+/yIpb+oRhJCCDkVCSKfNWsGl18Or77qVxIhhFCHIkHkuyOOgK5dvS/i22/TjiaEUEQiQeS7Bg28yusnn/iophBCqCPVThCS3s3cTspFQCGL7beH/v19XsRHH6UdTQihSFQ7QZhZJ2BH4MPaDyes0JVX+pKkZ52VdiQhhCKRZD2INTIlN5D020wdpYVm9nDOowvLtW3ryWHcOHjuubSjCSEUgSRXEM8Cq0pqDTwJHIWvERHq2llnQZs2Xu01hr2GEHIsSYKQmX0PHATcbGYH4mtMh7q2+ure1DR1qq8bEUIIOZQoQUjaDjgMWNas1Ch3IYVK9e8P220H554LC6PiSQghd5IkiMHAOcD4zHoOGwL/yW1YYYUkr/b62Wdw2WVpRxNCKGCVJghJDYH9zGx/M7sSwMxmmdnJdRJdyK5rVzjySLj+evjgg7SjCSEUqKrWg1gCbFNHsYTquPxyWGUVOPPMtCMJIRSoJE1Mr0maIOkISQctu+U8slC5Vq28mN/48fCfaPELIdS+JAliHeBLYDdgv8xt31wGFRI67TTYYAMf9rpkSdrRhBAKTJWjkczsqLoIJNTAaqv5wkK//z387W/wxz+mHVEIoYAkmUndRtJ4SZzxuj4AAA74SURBVJ9L+kzSA5La1EVwIYG+fWGnneC882DBgrSjCSEUkCRNTHcAE4BWQGvg35ltVZLUU9J0STMl/WLtTEk9JE2VVCapb4XXBkh6P3MbkOT9itKyYa9ffgkXX5x2NCGEApIkQbQ0szvMrCxzuxNoWdVBmSGyw4Be+Mzr/pIqzsCeAwwE7q1w7DrABcC2QDfgAklrJ4i1OHXpAn/4A9x0E8yYkXY0IYQCkWRG9BeSDgfuyzzvj3daV6UbMNPMZgFIGgP0Bt5ZtoOZzc68VrGw0F7ARDObn3l9ItCzXAyhoksv9UJ+p58O//532tGE2vbOO1BamnYUsOqqXn6+URRTKAZJ/pf/APwVuB4w4MXMtqq0BuaWe16KXxEkke3Y1hV3kjQIGATQrl27hKcuUOut5/0QZ58NTzwBv/td2hGF2nLTTT5SzSztSNw++8CYMdC0adqRhByrNEFkmon6mNn+NTi3smxL+hue6FgzGwmMBCgpKcmTv54UDR4MI0fCqafCG2/Et7z6bskSOOMMX1Gwd2+fFKlsfxp16OWXPY6dd4aHHoL11083npBTlX6CmNkSSb3xq4fqKgXalnveBvikGsfuUuHYp2sQQ3Fp0sRXnTvwQLj1VjgpFv2rt77/Hg4/3CdCnnwyXHcdNGyYdlTevLTJJj60unt3eOQR2HTTtKMKOZKkk/oFSX+VtJOkrZfdEhw3CegoqYOkxkA/fDRUEo8Dv5O0dqZz+neZbaEqvXvDbrvBBRfA/PlpRxNq4vPP/f/wwQf96uHGG/MjOSyz997w7LOweDHssAM89VTaEYUcSZIgtgc2BYYC12Zu11R1kJmVASfhH+zvAuMy1WCHZlalQ1JXSaXAwcAISdMyx84HLsaTzCRg6LIO61AFyT9UFiyACy9MO5pQXTNmeDn3N96ABx7wZsN8tPXW8MorvoBVz54wenTaEYUckFXS8ZVZarSvmY2ru5BqpqSkxCZPnpx2GPnj+OPhttvgzTehc6zvVC88/7xfATZs6CPRtk06piNFCxZAnz5+FXHRRXD++en3k4RqkTTFzEqyvVZVNdel+FVAqG+GDvVRJqedlj+jX8KKjR0Le+wBLVrASy/Vj+QAsNZa8OijXn7+ggt8Ps7ixWlHFWpJkiamiZLOkNRW0jrLbjmPLKycli39D/bxx70jMeQnM19Gtl8/X+fjxRdho43Sjqp6Gjf2JXAvuMDv99kHvv467ahCLai0iQlA0odZNpuZbZibkGommpiyWLwYNt/cH7/1lv8hh/xRVgZ/+pOPOOvXD+64wyei1WejRsExx/hIp0cegbZtqz4mpKrGTUwAZtYhyy2vkkNYgcaNfXjkjBkwbFja0YTyvv3W+xtuvRWGDIF77qn/yQFgwAB47DGYM8ebyV57Le2IwkpYYYKQdFa5xwdXeC0WQ64v9t4b9trLOxDnzUs7mgDwySfQo4c3/40Y4asDNkjS2ltP7L47vPCCT9Ts0cP7KEK9VNlvZb9yj8+p8FrPHMQSckHyq4hvv4W//CXtaMLbb/sEsxkzfKTSoEFpR5Qbm23ms647doT99vMZ/qHeqSxBaAWPsz0P+axzZzjhBP8jffPNtKMpXk8+6RPLysrgueegV6+0I8qtVq18Qt1ee/liVuecA0sr1uUM+ayyBGEreJztech3F17oQxJPPTWGvaZh1CifUNaunX+z7tIl7YjqRtOm8K9/eYK44go47DBYtCjtqEJClSWILSUtlPQNsEXm8bLnm9dRfKG2rLOOz4146in/gw11w8z7fwYOhF128clwxVZ5uFEjuOUWH847ZgzsuacvcBXyXpXDXOuLGOaaQFkZbLUV/PCDry/QpEnaERW2xYu9j2HUKE8QI0bEUOOxY31SXfv23nm9YQyITNtKDXMNBaRRI7j+epg1y+s1hdxZsMD7GEaN8iuI22+P5ABwyCHeF/PFF95Z/8oraUcUKhEJotjsuaePKrnkEvjvf9OOpjDNmQM77ugdtKNG+eixqE+03I47+ozxZs1g1129pHnIS5EgitG113pH4Z//nHYkhWfqVJ8gVlrq8xyOPDLtiPLTxht7zakttvBif3FFm5ciQRSjjh19EZo77vAPtFA7HnnEJ4Y1buwTxXbbLe2I8tuvfuWDJg44wEfXDR7sq+iFvBEJolidf75XDh08OIa91oZbb/Wmu4039mGsscpaMquvDvff72tu33QT9O3rq+mFvBAJolituab3Qzz/vP+BhppZuhTOPtvX3+jVC555JtZprq6GDX3wxI03+hDsXXf1VfVC6iJBFLOjj4Ytt/RF6H/4Ie1o6p8ff4RDD4WrrvIE8eCDPjEs1MzJJ3uH9Vtv+Qin6dPTjqjoRYIoZg0beufgnDnecR2S+/JLHxE2dqwniGHDfBhxWDm9e8PTT8N33/nSq889l3ZERS0SRLHbZRc46CCvKPrxx2lHUz988AFsvz1MmuQJ4swzYxhrberWzftxfvUrX2VvzJi0IypakSACXH21z7I+p2LR3vALL7/s32y//NInfP3+92lHVJg6dPC5Et27Q//+XscpBlPUuZwmCEk9JU2XNFPSkCyvN5E0NvP6K5LaZ7Y3lnSHpLckvSFpl1zGWfQ23NDXrr7rrpjZWpnx470DtXlzH8O/ww5pR1TY1lkHnnjC+3nOOQeOO86/yIQ6k7MEIakhMAzoBXQG+kvqXGG3o4GvzOw3wPXAlZntxwKY2ebAnsC1kuJqJ5fOPRd+/Wsfbhjf1H7phht8QtdWW3ly6Ngx7YiKQ5Mm/sXl3HO9XP1++8E336QdVdHI5YduN2Cmmc0ys8XAGKB3hX16A6Myj/8B7C5JeEJ5EsDMPgcWAFmLSYVa0qwZXHaZN6Hce2/a0eSPJUt8rsipp3pfzVNPQcuWaUdVXBo0gEsv9QQxcaJPRvzkk7SjKgq5HHbRGphb7nkpsO2K9jGzMklfA+sCbwC9JY0B2gLbZO5fzWG8YcAAH41z3HGeLIKPpvnoI2+Cu/rqwloatL459lho2xYOPthXrIv5JsttsQXcd1+tnzaXCSLbsI6KbRcr2ud2oBMwGfgIeBH4ReOjpEHAIIB2xVZjPxcaNPDL+UsvjUVdyrvgAjjqqLSjCOCLLj3/vCfr+B1drkOHnJw2lwmiFP/Wv0wboOJ14bJ9SiU1AtYE5psvUnHqsp0kvQi8X/ENzGwkMBJ8PYhajb5YdeoEd9+ddhQhrNiWW8bvaB3J5fXyJKCjpA6SGgP9gAkV9pkADMg87gs8ZWYmaXVJawBI2hMoM7N3chhrCCGECnJ2BZHpUzgJeBxoCNxuZtMkDQUmm9kE4O/AXZJmAvPxJALwK+BxSUuBj4EjchVnCCGE7GLJ0RBCKGKx5GgIIYRqiwQRQgghq0gQIYQQsooEEUIIIatIECGEELIqmFFMkubhs67rsxbAF2kHkUfi5/Fz8fNYLn4WP7cyP48NzCxrgbGCSRCFQNLkFQ03K0bx8/i5+HksFz+Ln8vVzyOamEIIIWQVCSKEEEJWkSDyy8i0A8gz8fP4ufh5LBc/i5/Lyc8j+iBCCCFkFVcQIYQQsooEkQcktZX0H0nvSpomaXDaMaVNUkNJr0l6KO1Y0iZpLUn/kPRe5ndku7RjSpOkUzN/J29Luk/SqmnHVJck3S7pc0lvl9u2jqSJkt7P3K9dG+8VCSI/lAGnm1knoDtwoqTOKceUtsHAu2kHkSduBB4zs02ALSnin4uk1sDJQImZbYYvJdCv8qMKzp1AzwrbhgBPmllH4MnM85UWCSIPmNmnZjY18/gb/AOgdbpRpUdSG2Af4G9px5I2Sc2BHvjaKZjZYjNbkG5UqWsErJZZhXJ1frlSZUEzs2fx9XPK6w2MyjweBRxQG+8VCSLPSGoPdAFeSTeSVN0AnAUsTTuQPLAhMA+4I9Pk9rdlqy0WIzP7GLgGmAN8CnxtZk+kG1VeWM/MPgX/wokvurbSIkHkEUlNgQeAU8xsYdrxpEHSvsDnZjYl7VjyRCNga+AWM+sCfEctNR/UR5m29d5AB6AVsIakw9ONqnBFgsgTklbBk8M9ZvbPtONJ0Q7A/pJmA2OA3SQV8wr1pUCpmS27ovwHnjCK1R7Ah2Y2z8x+Av4JbJ9yTPngM0nrA2TuP6+Nk0aCyAOShLcxv2tm16UdT5rM7Bwza2Nm7fHOx6fMrGi/IZrZf4G5kjbObNodeCfFkNI2B+guafXM383uFHGnfTkTgAGZxwOAf9XGSRvVxknCStsBOAJ4S9LrmW3nmtkjKcYU8sefgHskNQZmAUelHE9qzOwVSf8ApuKj/16jyGZVS7oP2AVoIakUuAC4Ahgn6Wg8iR5cK+8VM6lDCCFkE01MIYQQsooEEUIIIatIECGEELKKBBFCCCGrSBAhhBCyigQRwgpI+jYH55SkXTI3Zbb1kDRVUpmkvhX2H5Cp0Pm+pAHZzxpCbkSCCKGOSFoNr8S5WeZ2Z2bbHGAgcG+F/dfBx7hvC3QDLqitMs4hJBET5UKoQuab/lVAL8CAS8xsrKQGwF+BnYEP8S9ct5vZPzKlQsYCu2ZOc6iZzZR0PPBcZttOZvYDMDvzPhWLE+4FTDSz+ZnXJ+Jlnu/LyT80hAoiQYRQtYOArfC1GFoAkyQ9i8+Abw9sjlfPfBe4vdxxC82sm6QjgRskHQwMA+7IvD5M0gmZJJFNa2BuueelFHEZ+FD3ookphKrtCNxnZkvM7DPgGaBrZvv9ZrY0UzPpPxWOu6/c/XaZRPAH4O3M7Q+VJAcAZdkWpQ9CnYkriBCqlu2DurLty1jFx+a1bZ5O+L6leM2dZdpU49gQVlpcQYRQtWeBQzLrZLfEV3h7FXge6COpgaT1+PmHOcAh5e5fqsH7Pg78TtLamc7p32W2hVAn4goihKqNB7YD3sCvBM4ys/9KegAvN/02MANfBfDrcsc1kfQK/kWs/4pOLqlr5j3WBvaTdJGZbWpm8yVdDEzK7Dp0WYd1CHUhqrmGsBIkNTWzbyWti19V7JBJHrOBEjP7It0IQ6i5uIIIYeU8JGktoDFwcaazOoSCEFcQIYQQsopO6hBCCFlFggghhJBVJIgQQghZRYIIIYSQVSSIEEIIWUWCCCGEkNX/A09JGXNGJDfGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Sep 18 21:19:29 2020\n",
    "\n",
    "@author: DHRUV\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "HW1 1(d)\n",
    "i. B.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as lrn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "df_train=pd.read_csv('TrainingData.csv',index_col=0)\n",
    "print(df_train)\n",
    "\n",
    "df_test=pd.read_csv('TestData.csv',index_col=0)\n",
    "print(df_test)\n",
    "X=df_train.drop(columns=['O'])\n",
    "y=df_train['O']\n",
    "knn = KNeighborsClassifier(n_neighbors=5,weights='uniform',algorithm='auto',metric='minkowski',p=1)\n",
    "knn.fit(X,y)\n",
    "Z=df_test.drop(columns=['O'])\n",
    "test_prediction = knn.predict(Z)\n",
    "print(test_prediction)\n",
    "U=df_train.drop(columns=['O'])\n",
    "train_prediction = knn.predict(U)\n",
    "print(train_prediction)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This code performs KNN (Manhattan Distance Metric) as p=1\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "test=np.arange(100)\n",
    "train=np.arange(210)\n",
    "\n",
    "p=0\n",
    "q=0\n",
    "\n",
    "\n",
    "test_y = df_test['O'].to_numpy()\n",
    "train_y=df_train['O'].to_numpy()\n",
    "\n",
    "print(test_y)\n",
    "print(train_y)\n",
    "\n",
    "for i in test:\n",
    "    if test_y[i] != test_prediction[i]:\n",
    "        p=p+1\n",
    "\n",
    "for f in train:\n",
    "    if train_y[f] != train_prediction[f]:\n",
    "        q=q+1\n",
    "\n",
    "print(p)\n",
    "print(q)\n",
    "\n",
    "test_error=p/100\n",
    "train_error=q/210\n",
    "\n",
    "print(test_error)\n",
    "print(train_error)\n",
    "\n",
    "\"\"\"\n",
    "p are the test prediction mismatches\n",
    "q are the training prediction mismatches\n",
    "\n",
    "test_error and train_error are, respectively, the test error and the training error\n",
    "\n",
    "All this is only for k=5 for Manhattan\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "k = np.arange(1,197,5)\n",
    "print(k)\n",
    "\n",
    "size_k = np.size(k)\n",
    "print(size_k)\n",
    "\n",
    "ite=np.arange(size_k)\n",
    "print(ite)\n",
    "power_p=[10**0.1,10**0.2,10**0.3,10**0.4,10**0.5,10**0.6,10**0.7,10**0.8,10**0.9,10**1]\n",
    "p_range=np.size(power_p)\n",
    "p_index=np.arange(p_range)\n",
    "\n",
    "Test_Error_Vector = np.empty([size_k,p_range])\n",
    "Train_Error_Vector = np.empty([size_k,p_range])\n",
    "\n",
    "for h in ite:\n",
    "    for iota in p_index:\n",
    "      knn = KNeighborsClassifier(n_neighbors=k[h],weights='uniform',algorithm='auto',metric='minkowski',p=power_p[iota])\n",
    "      knn.fit(X,y)\n",
    "      test_prediction = knn.predict(Z)\n",
    "      train_prediction = knn.predict(U)\n",
    "      t=0\n",
    "      q=0\n",
    "      p=0\n",
    "      q=0 \n",
    "      for t in test:\n",
    "        if test_y[t] != test_prediction[t]:\n",
    "            p=p+1\n",
    "      for r in train:\n",
    "        if train_y[r] != train_prediction[r]:\n",
    "            q=q+1\n",
    "      Test_Error_Vector[h,iota]=(p/100)\n",
    "      Train_Error_Vector[h,iota]=(q/210)\n",
    "        \n",
    "\n",
    "print(Test_Error_Vector)\n",
    "print(Train_Error_Vector)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "The Error Vectors are no longer vectors but are matrices. The row corresponds to a value of k and \n",
    "column corresponds to a value of p\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Error_Test=pd.DataFrame(data=Test_Error_Vector,index=k,columns=['p1','p2','p3','p4','p5','p6','p7','p8','p9','p10'])\n",
    "print(Error_Test)\n",
    "Error_Train=pd.DataFrame(data=Train_Error_Vector,index=k,columns=['p1','p2','p3','p4','p5','p6','p7','p8','p9','p10'])\n",
    "print(Error_Train)\n",
    "\n",
    "\"\"\"\n",
    "Converting array to a more readable dataframe of errors, p's written sequential\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Error_Test.to_csv('Error_Test.csv')\n",
    "Error_Train.to_csv('Error_Train.csv')\n",
    "\n",
    "\"\"\"\n",
    "Converting to csv to visualize and decide p\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Upon examining the data, there doesn't seem to be an \"overall\" best value of p\n",
    "\n",
    "Now to examine trend of p corresponding to k*=16 selected in HW1_d_i_A\n",
    "\n",
    "We'll draw error vs p curves for a given k*=16\n",
    "\"\"\"\n",
    "\n",
    "e_test = Error_Test.loc[16]\n",
    "e_train = Error_Train.loc[16]\n",
    "\n",
    "\n",
    "\n",
    "y=[1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "plt.plot(y,e_test,'r')\n",
    "plt.plot(y,e_train,'b')\n",
    "plt.xlabel('logp*10')\n",
    "plt.ylabel('Errors, red = test, blue = training')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "From the plot for k*=16,\n",
    "we can clearly see that \n",
    "logp = 0.6 minimizes the training error and the test error though not minimized, is\n",
    "sufficiently low\n",
    "logp= 0.8 and logp=1 also minimize the test error, but the training error does increase moderately\n",
    "\n",
    "So\n",
    "logp=0.6 is an optimal point \n",
    "\n",
    "(we can also include 0.8 and 1 as they don't perform badly either)\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
